{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "99.1-speedup_image_loading.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asciotti/neural-sar/blob/master/99_1_speedup_image_loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWoLt-co4lg4",
        "colab_type": "text"
      },
      "source": [
        "# Experiment to speed up data loading\n",
        "\n",
        "Right now model takes ~20-30 minutes to train 256x256 images starting w/ 32 filters on the front and end CNN. Noticed that the loading of images was extremely slow, up to 1-2 seconds per batch of ~32 images. Given 32 random images are loaded every step for 32 steps per epoch for 20 epochs this would be roughly 10-20 minutes of training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z6-_2iwTGAz",
        "colab_type": "code",
        "outputId": "820aedbb-67eb-4a26-f4d9-66b2fbad023f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from skimage.util import random_noise\n",
        "from skimage import io\n",
        "import os\n",
        "import importlib\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ7UX7MB6SU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.io import imread, imread_collection, ImageCollection\n",
        "from skimage.transform import resize\n",
        "from skimage.color import rgb2lab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPKzC8MTSfqW",
        "colab_type": "text"
      },
      "source": [
        "## TL;DR - Results\n",
        "\n",
        "### Setup: Randomly select batches of 32 images from a corpus of 1000 images 10 times\n",
        "\n",
        "### Old Method: ~35 seconds\n",
        "\n",
        "###New Method: ~15 seconds\n",
        "\n",
        "Note that with the old method, this is a ~linear retrieval rate because no caching occurs. With the new method, the retrieval rate is not linear because images are cached (though at the expense of memory), thus after the initial loading, retrieval is merely list indexing.\n",
        "\n",
        "Note, and attempt to individually time events (i.e. loading vs indexing) was difficult due to the different methods and some annoyances with trying to control for caching within the notebook. Ultimately, the initial results speak for themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVLYxRE96MKT",
        "colab_type": "text"
      },
      "source": [
        "## Old method of loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7QNyhdGTIhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input(name):\n",
        "    \n",
        "    img = imread('/content/drive/My Drive/Colab Notebooks/1_ft_ortho_images/'  + str(int(name)) + '.png', as_gray=False) #Note in production this would be as_gray=True\n",
        "    img = resize(img, (256,256,1))\n",
        "    if np.max(img) > 1:\n",
        "      img = img/255.0\n",
        "    \n",
        "    return(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uco1YlOTbbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_output(name):\n",
        "    \n",
        "    img = imread('/content/drive/My Drive/Colab Notebooks/1_ft_ortho_images/'  + str(int(name)) + '.png', as_gray=False)\n",
        "    img = resize(img, (256,256,3))\n",
        "    if np.max(img) > 1:\n",
        "      img = img/255.0\n",
        "    return(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnFRU3I8TR8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_generator(indices,batch_size = 32):\n",
        "    \n",
        "    while True:\n",
        "          # Select files (paths/indices) for the batch\n",
        "          batch_paths = np.random.choice(a = indices, \n",
        "                                         size = batch_size)\n",
        "          batch_input = []\n",
        "          batch_output = [] \n",
        "#           print(batch_paths[0], batch_paths[-1])\n",
        "          \n",
        "          # Read in each input, perform preprocessing and get labels\n",
        "          for input_path in batch_paths:\n",
        "              input = get_input(input_path)\n",
        "              output = get_output(input_path)\n",
        "              batch_input += [ input ]\n",
        "              batch_output += [ output ]\n",
        "          # Return a tuple of (input,output) to feed the network\n",
        "          batch_x = np.array( batch_input )\n",
        "          batch_y = np.array( batch_output )\n",
        "        \n",
        "          yield( batch_x, batch_y )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dhta3hsTT47",
        "colab_type": "code",
        "outputId": "b4993fdf-31d5-43ce-e980-4bbc8dce4c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "x = image_generator(range(1,1000),batch_size=32)\n",
        "imgs = [x.__next__() for y in range(10)]\n",
        "print('Final # of images ',len(imgs))\n",
        "print('Old method loading data times:')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final # of images  10\n",
            "Old method loading data times:\n",
            "CPU times: user 35.8 s, sys: 29.8 s, total: 1min 5s\n",
            "Wall time: 35.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW2EilZvSWEE",
        "colab_type": "text"
      },
      "source": [
        "## New method of loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obxrrTnrTUzD",
        "colab_type": "code",
        "outputId": "58f2fc76-491d-4a75-81af-ebc2e6044c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "arr = ['/content/drive/My Drive/Colab Notebooks/1_ft_ortho_images/{}.png'.format(x) for x in range(1,1000)]\n",
        "# print(arr)\n",
        "IC = imread_collection(arr, conserve_memory=False)\n",
        "imgs2 = []\n",
        "for i in range(10):\n",
        "    choices = np.random.choice(a = len(IC), size = 32)\n",
        "    _imgs = np.stack([resize(IC[x], (256,256,3))/255.0 for x in choices])\n",
        "    imgs2.append(_imgs)\n",
        "print('Final # of images ',len(imgs2))\n",
        "print('New method loading data times:')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final # of images  10\n",
            "New method loading data times:\n",
            "CPU times: user 14.4 s, sys: 13.1 s, total: 27.5 s\n",
            "Wall time: 15.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}